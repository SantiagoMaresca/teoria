\section{Procesos}

``Informalmente, un proceso es un programa en ejecución. Además de código, un proceso incluye también la actividad actual, que
está formada por el valor del contador del programa y el contenido de los registros del procesador.
Cada proceso se representa en el sistema operativo mediante su propio bloque de control de proceso.''\cite{silberschatz}.

Generalmente, un proceso también incluye una pila, que contiene datos temporales, y una sección de datos, 
que contiene las variables globales.
\cite{silberschatz}.

\subsection{Estados de un proceso}

Los procesos de un sistema pueden encontrarse (en principio) en uno de 5 estados, que reflejan su actividad actual.

\begin{description}
	\item[Nuevo:] El proceso está siendo creado en el sistema.
	\item[Listo:] El proceso está a la espera de que lo asignen a un procesador.
	\item[Ejecución:] Se están ejecutando sus instrucciones. Tiene control de la CPU.
	\item[Bloqueado:] El proceso está en espera de que se produzca un suceso.
	\item[Terminado:] El proceso ha terminado su ejecución.
\end{description}

\subsection{Planificación de Procesos}

En un sistema de multiprocesamiento, los procesos (y eventualmente los hilos de kernel) compiten por el control de la CPU.
Cuando la cantidad de tareas\footnote{Procesos o hilos de kernel} supera a la cantidad de procesadores es evidente que algunas
deben esperar a que se libere alguno de ellos. Entonces, cuando no se esta ejecutando, se encuentra en alguna cola de espera.
Con la multiprogramación se busca utilizar al sistema de manera eficiente, permitiendo la ejecución de múltiples tareas de la mejor forma posible.
A modo de ejemplo, cuando una tarea tiene que esperar por una operación de E/S se planifica a otra en el procesador.
El algoritmo que decide qué tarea obtendrá control de la CPU se dice un \emph{planificador a corto plazo}\cite{silberschatz}.

Una de los aspectos que se busca de un planificador a corto plazo es que el tiempo de ejecución sea mínimo, así como el de espera.
El tiempo de ejecución es el intervalo que va desde el instante en que se ordena la ejecución de una tarea hasta el instante en que se completa \cite{silberschatz}.
El de espera\label{tiempo-espera} se define como la suma de los períodos en que la tarea se encuentra en el estado \emph{Listo}.

\subsubsection{Esquemas de Planificación}

Con el fin de no tener una CPU desocupada el planificador asigna siempre una nueva tarea cuando la tarea que se encontraba en ejecución pasa al estado de \emph{Bloqueado} o \emph{Terminado} \cite{catedra-planificacion}.
Algunos planificadores deciden, además, elegir un nuevo proceso (o al menos permitirse hacerlo) en las transiciones:
\begin{itemize}
	\item de \emph{Bloqueado} a \emph{Listo}
	\item de \emph{Ejecución} a \emph{Listo} (e.g.\ Al ocurrir una interrupción)
\end{itemize}

Estos algoritmos se dicen algoritmos de esquema \emph{apropiativo}.
Aquellos que no sean apropiativos se dicen de esquema \emph{cooperativo} o \emph{sin desalojo}.


\subsubsection{First Come, First Serve}\label{fcfs}

El algoritmo \emph{FCFS} es el más simple de los planificadores a corto plazo.
Con este esquema se asigna control de la CPU a la primer tarea que lo solicite.
Su implementación consiste en tomar a la cola de trabajos preparados (aquellos en estado \emph{Listo}) como una cola \textbf{FIFO}.
Este algoritmo es uno de esquema \emph{cooperativo}.

A pesar de la simplicidad del algoritmo (o a costas de ella) la planificación FCFS posee dos cualidades no particularmente deseables.
En primer lugar, el tiempo medio de espera (ver página \pageref{tiempo-espera}) es bastante largo\cite{silberschatz}.
Además, presenta un comportamiento conocido con el nombre de \emph{efecto convoy}.

Los trabajos de un sistema informático pueden verse como una cadena de dos clases de estado: ráfaga de CPU y ráfaga de E/S.
En ciertas ocasiones puede suceder que muchas tareas (que finalizaron su ráfaga de E/S y están en espera de que se les asigne CPU)
se vean incapacitadas de continuar porque deben esperar a que \emph{un} proceso acabe libere la CPU.
Esto se conoce como efecto convoy, y da lugar a una utilización de la CPU y los
   dispositivos menor que si se permitiera a procesos mas cortos ejecutar primero.

\subsubsection{Planificación por prioridades}

En este algoritmo se asocia con cada tarea una prioridad, y al momento de elegir un nuevo proceso se toma a aquel de mayor prioridad.
El mismo puede ser de cualquier esquema, apropiativo o cooperativo.

La prioridad no está definida a-priori, y es algo que dependerá del sistema particular que esté bajo consideración.
Ella puede ser definida de dos maneras, interna o externamente.

La prioridad definida internamente utiliza alguna medida de la tarea para calcularla.
Un ejemplo de esto es la planificación SJF (\emph{Shortest Job First}) que estima
(típicamente mediante una media exponencial) la duración de la próxima ráfaga de CPU.
Esto le permite ejecutar el trabajo más corto primero (evitando el efecto convoy).

La prioridad definida externamente es asignada mediante algún mecanismo por el usuario.

El mayor problema de estos algoritmos, sin importar su definición de prioridad, es el \emph{bloqueo indefinido} o \emph{muerte por inanición}\cite{silberschatz}.
Cuando muchas tareas de alta prioridad buscan ejecutarse no permiten a aquellas de menor prioridad obtener control de la CPU.
Si esta situación se mantiene por un intervalo significativo podría afectar la experiencia del usuario y,
con un flujo estable de tareas de alta prioridad, podría evitar de forma completa la finalización de esta tarea.

Una solución a este problema es el mecanismo de \emph{envejecimiento}.
Bajo este marco se aumenta gradualmente la prioridad de las tareas que están esperando CPU, garantizando su eventual ejecución.

\section{Hilos}
El modelo de proceso discutido en clase implica que un proceso es un programa que realiza un 
solo hilo de ejecución. ``Por ejemplo, cuando un proceso está ejecutando un procesador 
de textos, un solo hilo de instrucciones se está ejecutando. Este único hilo de control permite 
que el proceso realice solo una tarea a la vez. Por ejemplo, el usuario no puede escribir simultáneamente 
caracteres y ejecutar el corrector ortográfico dentro del mismo proceso. 
La mayoría de los sistemas operativos modernos han extendido el concepto de proceso para 
permitir que un proceso tenga múltiples hilos de ejecución y así realizar más de una tarea 
al mismo tiempo.'' Esta característica es especialmente beneficiosa en sistemas multiprocesador, 
donde se pueden ejecutar múltiples hilos en paralelo.\cite{silberschatz}

``Un hilo es un flujo de control dentro de un proceso. Un proceso multihilo contiene varios 
flujos de control diferentes dentro del mismo espacio de direcciones.
Los beneficios de los mecanismos multihilo incluyen una mayor capacidad de respuesta para 
el usuario, la compartición de recursos dentro del proceso, una mayor economía y los factores 
de escalabilidad, como un uso más eficiente de múltiples núcleos de procesamiento.
Los hilos de nivel de usuario son hilos que son visibles para el programador y son desconocidos
para el kernel. El kernel del sistema operativo soporta y administra hilos de nivel de kernel. 
En general, los hilos de usuario son más rápidos de crear y gestionar que los hilos del kernel, 
porque no se requiere intervención del kernel.''\cite{silberschatz}
Existen tres tipos diferentes de modelos que relacionan los hilos de usuario y del kernel:
\begin{itemize}
	\item El modelo muchos-a-uno asigna muchos hilos de usuario a un solo hilo del kernel. 
	\item El modelo uno-a-uno asigna cada hilo de usuario a un hilo de kernel correspondiente.
	\item El modelo muchos-a-muchos multiplexa muchos hilos de usuario a un número menor o igual de hilos del kernel.
\end{itemize}

\subsection{Modelos y Ámbitos de contienda}

El modelo muchos-a-muchos presenta un esquema en que \emph{dos} planificaciones deben llevarse a cabo.
En primer lugar, los hilos de usuario creados deben ser planificados cada uno en un hilo de kernel (si quedan disponibles).
Esto se conoce como ámbito de contienda de proceso (PCS)\cite{silberschatz}, ya que quienes compiten son únicamente los hilos del proceso en cuestión.
Por otro lado, los hilos de kernel planificados sobre la(s) CPU(s) compiten con hilos de otros procesos (de todo el sistema), por lo que se conoce como ámbito de contienda de sistema (SCS).
Comúnmente, el PCS sigue un esquema de prioridades para la planificación.



\section{Memoria compartida}

Uno de los problemas en los sistemas multiproceso es controlar el acceso a la
memoria. Si todos ejecutan de manera libre y
descontrolada podrían escribir en la misma dirección, acabando eventualmente con un estado de
memoria incoherente.

Además, según como ocurra la planificación del procesador, los resultados podrían
ser diferentes cada vez, haciendo impredecible la ejecución de los procesos.

La forma en que resuelven este problema los sistemas es múltiple. Una clara
opción es dar a cada proceso un espacio de memoria determinado y prohibir el
acceso de un proceso al espacio de otro. El problema de esta solución es que
algunas veces es conveniente poder compartir memoria entre procesos, ya sea para
que se comuniquen o para dividir el trabajo.

\subsection{Problema de los lectores-escritores}
Cuando un conjunto de datos es compartido por varios procesos concurrentes, unos buscan leer y otros escribir.
Para distinguirlos llamamos \emph{lectores} a los primeros y \emph{escritores} a los segundos\cite{silberschatz}.
En este marco podemos detallar los casos que presentan una situación de riesgo y que deben ser controladas.
Si dos o más lectores acceden a los datos esto no presenta ningún inconveniente.
Sin embargo, si un escritor accede a los datos ningún otro (lector o escritor) deberá hacerlo.

\subsubsection{Variantes}
En el \emph{primer} problema de lectores-escritores,
ningún lector se mantiene en espera a menos que un escritor haya obtenido ya permiso para el objeto
compartido \cite{silberschatz}.

El \emph{segundo} problema trata del caso en que un escritor preparado realiza la operación tan pronto como sea posible \cite{silberschatz}.

Este ultimo caso es el de nuestro sistema, ya que queremos que la compra se efectué tan rápido como sea posible.

\subsection{Bloqueo y Sincronización}
Para controlar el problema se busca controlar el acceso a esta memoria.
Se busca evitar de alguna manera que dos procesos modifiquen la misma locación de manera concurrente.
Una manera es hacerlo mediante semáforos.

\subsubsection{Semáforos}
Un semáforo es una variable a la cual se accede únicamente mediante dos
operaciones atómicas: \call{wait()} y \call{signal()} \cite{silberschatz}.
Posee dos propiedades: \emph{value} que es un entero y \emph{list} una lista de bloques de control de procesos.
Una posible implementación de estas operaciones es la que se muestra en el listado \ref{lst:wait-sem}.

El segmento de código en que un proceso modifica memoria compartida se conoce como \emph{sección crítica} \cite{silberschatz}.
Mediante estas
operaciones es posible crear bloques de código de sección crítica que no tendrán
colisión con otros procesos (o eventualmente hilos) que también respeten al
semáforo.

De esta manera, si el acceso a una estructura compartida es controlado mediante
semáforos es posible asegurar la consistencia e integridad de los datos.

En el caso, el conjunto de entradas disponibles y vendidas, compartida por los
múltiples servicios de venta, podría ser visto como una estructura a sincronizar
entre ellos, asegurando que cuando uno toma una entrada ningún otro lo hace.

\lstinputlisting[float,caption=Implementaci\'on de un sem\'aforo,label={lst:wait-sem}]{../../../informe/wait.c}


\subsubsection{Interbloqueos}

Un proceso que está en espera por la liberación de un recurso\footnote{Como puede ser un semáforo} no podrá ejecutar hasta que el sistema se lo asigne.
Sin embargo, mientras se encuentra esperando puede llegar a tener otros recursos bajo su control.

Imaginemos un grafo cuyos vértices son los procesos y recursos del sistema.
Si un proceso está en espera de un recurso existirá una arista desde el proceso \(P_i\) hasta el recurso, \(R_j\).
Si un proceso posee un recurso existirá una arista desde el recurso \(R_j\) hasta este proceso, \(P_k\).

\begin{center}
\begin{tikzpicture}
\def \n {4}
\def \radius {3cm}
\def \margin {8}
  \node[draw, circle] at ({360/\n * (0)}:\radius) {$P_i$};
  \draw[->, >=latex] ({360/\n * 0+\margin}:\radius)
    arc ({360/\n * 0+\margin}:{360/\n * (1)-\margin}:\radius);
  \node[draw, circle] at ({360/\n * (1)}:\radius) {$R_j$};
  \draw[->, >=latex] ({360/\n * 1+\margin}:\radius)
    arc ({360/\n * 1+\margin}:{360/\n * (2)-\margin}:\radius);
  \node[draw, circle] at ({360/\n * (2)}:\radius) {$P_k$};
  \draw[->, >=latex] ({360/\n * 2+\margin}:\radius)
    arc ({360/\n * 2+\margin}:{360/\n * (3)-\margin}:\radius);
  \node[draw, circle] at ({360/\n * (3)}:\radius) {$R_h$};
  \draw[->, >=latex] ({360/\n * 3+\margin}:\radius)
    arc ({360/\n * 3+\margin}:{360/\n * (4)-\margin}:\radius);
\end{tikzpicture}
\end{center}

Pero si analizamos la situación en que un ciclo se dé en este grafo (con el camino \(P_i,R_j,P_k,R_h\)) encontramos un problema.
Ambos procesos esperan por un recurso, pero ninguno de los dos lo obtendrá hasta que el otro libere el que tiene en su posesión,
cosa que no hará hasta obtener el recurso que espera.
La figura A continuación mostramos un par de hilos que entran en interbloqueo esperando por dos semáforos.

\begin{center}
\begin{tabular}{|l|l|}
	Hilo A & Hilo B \\ \hline
	wait(Sem1) & wait(Sem2) \\
	wait(Sem2) & wait(Sem1) \\
	\multicolumn{2}{|c|}{// Nunca ejecuta} \\
	signal(Sem1) & signal(Sem2) \\
	signal(Sem2) & signal(Sem1) \\
	\hline
\end{tabular}
\end{center}
